{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.05 s, sys: 253 ms, total: 1.3 s\n",
      "Wall time: 1.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.layers import Input, Dense, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import optimizers, activations, losses\n",
    "\n",
    "\n",
    "NUM_CUSTS = 2000\n",
    "NUM_PRODS = 40\n",
    "NUM_WEEKS = 49\n",
    "WINDOW_SIZE = 4\n",
    "ROW_INP_LEN = NUM_PRODS*2+WINDOW_SIZE+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 14s, sys: 2.48 s, total: 2min 17s\n",
      "Wall time: 2min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def load_train_data(random_state=123, valid_size=0.1):\n",
    "    \"\"\"\n",
    "    Load train/test data from disk and perform preprocessing to prepare it for classifiers.\n",
    "    \n",
    "    Returns:\n",
    "    - X_train, y_train, X_val, y_val, X_test\n",
    "    \"\"\"\n",
    "    def cast(x):\n",
    "        try:\n",
    "            return float(x)\n",
    "        except:\n",
    "            return 0\n",
    "    \n",
    "    X = np.zeros((NUM_CUSTS, NUM_PRODS, NUM_WEEKS, ROW_INP_LEN))\n",
    "    X_test = np.zeros((NUM_CUSTS, NUM_PRODS, 1, ROW_INP_LEN))\n",
    "    y = np.zeros((NUM_CUSTS, NUM_WEEKS, NUM_PRODS))\n",
    "\n",
    "    df = pd.read_csv('./train.csv')\n",
    "\n",
    "    # Add \"discount\" column\n",
    "    org_price = df.loc[(df['advertised'] == 0), ['j', 'price']].drop_duplicates().sort_values('j')['price'].values\n",
    "    df['discount'] = df.apply(lambda row: 1-row['price']/org_price[int(row['j'])], axis=1)\n",
    "\n",
    "    # pre-init of useful conditions\n",
    "    cond_i = [df['i'] == i for i in range(NUM_CUSTS)]\n",
    "    cond_j = [df['j'] == j for j in range(NUM_PRODS)]\n",
    "    cond_t = [df['t'] == t for t in range(NUM_WEEKS)]\n",
    "\n",
    "    # Specify product by value, value = how much prod_j is been purchased\n",
    "    # ex. prod_0 = 3251, prod_6 = 16190\n",
    "    # np.log1p: for normalization\n",
    "    prod_val = [np.log1p(len(df[cond_j[j]])) for j in range(NUM_PRODS)]\n",
    "    \n",
    "    # Represent user by vector, vector = how much user_i purchased prod_j\n",
    "    # ex. user_0 = [2 2 1 ... 0 0 4], user_2 = [0 2 0 ... 0 0 5]\n",
    "    # makes sort of uniqe identity and relation between simmiler users\n",
    "    user_vec = [[np.log1p(len(df[cond_i[i] & cond_j[j]]))\n",
    "                 for j in range(NUM_PRODS)] for i in range(NUM_CUSTS)]\n",
    "    \n",
    "    # Discount history\n",
    "    disc_his = [[cast(df.loc[cond_j[j] & cond_t[t], 'discount'].drop_duplicates())\n",
    "                 for t in range(NUM_WEEKS)] for j in range(NUM_PRODS)]\n",
    "    \n",
    "    # Advertise history\n",
    "    advr_his = [[cast(df.loc[cond_j[j] & cond_t[t], 'advertised'].drop_duplicates())\n",
    "                 for t in range(NUM_WEEKS)] for j in range(NUM_PRODS)]\n",
    "    \n",
    "    # Fill in y with output-labels\n",
    "    for i in range(NUM_CUSTS):\n",
    "        for t in range(NUM_WEEKS):\n",
    "            # Labels all the products purchased by user_i in week_t\n",
    "            y[i, t, df.loc[cond_i[i] & cond_t[t], 'j'].values] = 1\n",
    "    \n",
    "    # Fill in the input-metrix X\n",
    "    for i in range(NUM_CUSTS):\n",
    "        for j in range(NUM_PRODS):\n",
    "            for t in range(WINDOW_SIZE, NUM_WEEKS):\n",
    "                # [0:NUM_PRODS]: user_i vector\n",
    "                X[i, j, t, :NUM_PRODS] = user_vec[i]\n",
    "                # [NUM_PRODS:NUM_PRODS*2]: prod_j vector \"one hot vector\"\n",
    "                X[i, j, t, NUM_PRODS+j] = 1\n",
    "                # [NUM_PRODS*2]: prod_j value\n",
    "                X[i, j, t, NUM_PRODS*2] = prod_val[j]\n",
    "                # [NUM_PRODS*2+1]: prod_j discount in week_t\n",
    "                X[i, j, t, NUM_PRODS*2+1] = disc_his[j][t]\n",
    "                # [NUM_PRODS*2+2]: is prod_j advertised in week_t\n",
    "                X[i, j, t, NUM_PRODS*2+2] = advr_his[j][t]\n",
    "                # [NUM_PRODS*2+3:NUM_PRODS*2+2+WINDOW_SIZE]: user_i purchases history of prod_j\n",
    "                X[i, j, t, NUM_PRODS*2+3:] = y[i, t-WINDOW_SIZE:t, j]\n",
    "    \n",
    "    # Fill in the test input-metrix X_test\n",
    "    tps = pd.read_csv('./promotion_schedule.csv')\n",
    "    cond_j_test = [tps['j'] == j for j in range(NUM_PRODS)]\n",
    "    for i in range(NUM_CUSTS):\n",
    "        for j in range(NUM_PRODS):\n",
    "            X_test[i, j, 0, :NUM_PRODS] = user_vec[i]\n",
    "            X_test[i, j, 0, NUM_PRODS+j] = 1\n",
    "            X_test[i, j, 0, NUM_PRODS*2] = prod_val[j]\n",
    "            X_test[i, j, 0, NUM_PRODS*2+1] = cast(tps.loc[cond_j_test[j], 'discount'])\n",
    "            X_test[i, j, 0, NUM_PRODS*2+2] = cast(tps.loc[cond_j_test[j], 'advertised'])\n",
    "            X_test[i, j, 0, NUM_PRODS*2+3:] = y[i, -WINDOW_SIZE:, j]\n",
    "    \n",
    "    # Reshape X, X_test and y\n",
    "    X = X[:, :, WINDOW_SIZE:].reshape(-1, ROW_INP_LEN)\n",
    "    X_test = X_test.reshape(-1, ROW_INP_LEN)\n",
    "    y = y[:, WINDOW_SIZE:].transpose((0, 2, 1)).reshape(-1, 1)\n",
    "    y = np.concatenate((y.astype(np.int8), (y == 0).astype(np.int8)), axis=1)\n",
    "    \n",
    "    # Split X and y to train and valid sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=random_state, valid_size=valid_size)\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test\n",
    "\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test = load_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH 0, ROC-AUC Valid] 0.865060010432247\n",
      "[EPOCH 1, ROC-AUC Valid] 0.8843904142782171\n",
      "[EPOCH 2, ROC-AUC Valid] 0.8942961787784827\n",
      "[EPOCH 3, ROC-AUC Valid] 0.8956277427320496\n",
      "[EPOCH 4, ROC-AUC Valid] 0.8965357004066832\n",
      "[EPOCH 5, ROC-AUC Valid] 0.8979278411671864\n",
      "[EPOCH 6, ROC-AUC Valid] 0.8980160118058149\n",
      "[EPOCH 7, ROC-AUC Valid] 0.8986029549049459\n",
      "[EPOCH 8, ROC-AUC Valid] 0.8987987514061534\n",
      "[EPOCH 9, ROC-AUC Valid] 0.8986597412090079\n",
      "CPU times: user 4min 51s, sys: 29.9 s, total: 5min 21s\n",
      "Wall time: 3min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_model():\n",
    "    inp = Input(shape=[X_train.shape[1]])\n",
    "    \n",
    "    h_layer = BatchNormalization() (Dense(128, activation=lambda x: activations.elu(x, alpha=0.8)) (inp))\n",
    "    h_layer = Dense(32, activation=lambda x: activations.elu(x, alpha=0.2)) (h_layer)\n",
    "    h_layer = Dense(8, activation=lambda x: activations.elu(x, alpha=0.05)) (h_layer)\n",
    "    \n",
    "    output = Dense(2, activation=activations.softmax) (h_layer)\n",
    "    \n",
    "    model = Model([inp], output)\n",
    "    model.compile(loss=losses.binary_crossentropy, optimizer=optimizers.Adam(lr=3e-3, beta_1=0.92, beta_2=0.94))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_model()\n",
    "for i in range(10):\n",
    "    model.fit(X_train, y_train, epochs=1, batch_size=2**(8+i), class_weight=\"balenced\", verbose=0)\n",
    "    print(\"[EPOCH {}, ROC-AUC Valid] {}\".format(i, roc_auc_score(y_val, model.predict(X_val, batch_size=512))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 760 ms, sys: 39.1 ms, total: 799 ms\n",
      "Wall time: 743 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_test = model.predict(X_test, batch_size=512)[:, 0]\n",
    "submission = pd.DataFrame([[i, j, y_test[i*NUM_PRODS+j]] for i in range(NUM_CUSTS) for j in range(NUM_PRODS)],\n",
    "             columns=['user_id', 'product_id', 'prediction'])\n",
    "submission.to_csv(\"week_50_predictions.csv\", index=False, float_format='%.17f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
